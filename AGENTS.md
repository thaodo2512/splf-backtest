# Repository Guidelines

## Project Structure & Module Organization
- `splf/` Core library modules:
  - `data_handler/` raw→1m builders; file I/O helpers.
  - `feature_engine/` SPLF feature computation and 5m resampling.
  - `backtesting/` walk‑forward runner, labeling, metrics.
  - `modeling/` Isolation Forest model (CPU/GPU backends).
  - `utils/` YAML/Parquet utilities; `notebook.py` Jupyter API.
- `scripts/` CLI entry points: `download_data.py`, `build_minute_bars.py`, `compute_features.py`, `run_backtest.py`, `analyze_results.py`.
- `config/` Runtime configuration (`config.yaml`).
- `data/`, `artifacts/`, `outputs/` Generated by the pipeline; git‑ignored.
- `notebooks/` Research notebooks (keep lightweight in PRs).

## Build, Test, and Development Commands
- Environment (pyenv + conda)
  - `pyenv local miniforge3-24.11.3-2`
  - `conda create -n splf -y` (first time)
  - `conda activate splf`
  - `pip install -r requirements.txt`
- Pipeline
  - `python scripts/download_data.py --config config/config.yaml`
  - `python scripts/build_minute_bars.py --config config/config.yaml`
  - `python scripts/compute_features.py --config config/config.yaml`
  - `python scripts/run_backtest.py --config config/config.yaml`
  - `python scripts/analyze_results.py --config config/config.yaml`
  - Visualize minute bars: `python scripts/visualize_minute_bar.py --config config/config.yaml --symbol BTCUSDT --show`
- Optional tools (if installed): `black .`, `ruff .` for quick style checks.
 - Environment check: `python scripts/check_env.py` (CPU cores, RAM, GPU/cuML availability).

## Coding Style & Naming Conventions
- Python 3; PEP 8; 4‑space indentation; type hints where practical.
- Modules and functions use `snake_case`; classes `CamelCase`.
- DataFrames are UTC‑indexed by minute; prefer pure functions that return new frames. Use `splf.utils.io.ensure_dir`/`save_*` for writes.

## Testing Guidelines
- Framework: `pytest` (not bundled). Place tests in `tests/` with `test_*.py`.
- Favor synthetic, small inputs. Validate shapes, column presence, monotonic UTC index, and determinism (e.g., `compute_features_1m`, `run_walk_forward`).
- Run: `pytest -q` or target a file: `pytest tests/test_features.py -q`.

## Commit & Pull Request Guidelines
- Commits: imperative mood; focused scope. Prefer conventional prefixes (`feat:`, `fix:`, `docs:`, `refactor:`).
- PRs must include: goal summary, config snippet (`config/config.yaml` diffs or sample), reproduction steps, and sample outputs paths (e.g., `artifacts/alerts/BTCUSDT.csv`).
- Do not commit data/artifacts/notebooks outputs; they are git‑ignored.

## Security & Configuration Tips
- Data uses Binance public dumps; downloads are large. Adjust `universe`, `period`, and `datasets.*` to control volume.
- Parallelism via `runtime.workers`. For GPU, set `model.backend: cuml` (requires RAPIDS); otherwise `auto`/`sklearn`.
  - Set `runtime.workers: 0` or `auto` to auto-detect cores (bounded by symbol count).
- Use `--force` flags and `runtime.force` cautiously to overwrite existing files.

### GPU on Jetson
- Prefer conda (Miniforge). Try: `conda install -n splf -c conda-forge cupy`.
- For cuML: `conda install -n splf -c rapidsai -c conda-forge cuml` (availability on Jetson/ARM varies by JetPack/CUDA; consult RAPIDS docs).
- Verify with `python scripts/check_env.py` (should report GPU devices and `cuml` version).

## Agent-Specific Instructions
- Role: Act as a professional developer building the SPLF backtest trading tool.
- Specs: Treat `SPLF_Offline_Backtest_Spec_Binance.md` and `backtest_spec.md` as sources of truth; align data fields, event definitions, and metrics with them.
- TODO.md: Maintain a root `TODO.md`. If missing, create it. Include current goal, decisions, next steps, and exact commands to run; update after each change.
- Debugging: When issues arise, read `debug.log` at the repo root (git‑ignored), reproduce locally, locate the faulty module, implement a minimal fix with a targeted test, and keep logs out of commits.
